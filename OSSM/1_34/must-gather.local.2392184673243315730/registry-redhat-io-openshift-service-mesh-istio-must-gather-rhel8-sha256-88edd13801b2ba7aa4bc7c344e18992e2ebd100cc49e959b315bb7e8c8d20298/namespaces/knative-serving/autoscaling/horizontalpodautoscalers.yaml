---
apiVersion: autoscaling/v2
items:
- apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"autoscaling/v2","kind":"HorizontalPodAutoscaler","metadata":{"labels":{"app.kubernetes.io/component":"activator","app.kubernetes.io/name":"knative-serving","app.kubernetes.io/version":"release-v1.14"},"name":"activator","namespace":"knative-serving","ownerReferences":[{"apiVersion":"operator.knative.dev/v1beta1","blockOwnerDeletion":true,"controller":true,"kind":"KnativeServing","name":"knative-serving","uid":"aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c"}]},"spec":{"maxReplicas":21,"metrics":[{"resource":{"name":"cpu","target":{"averageUtilization":100,"type":"Utilization"}},"type":"Resource"}],"minReplicas":2,"scaleTargetRef":{"apiVersion":"apps/v1","kind":"Deployment","name":"activator"}}}
      manifestival: new
    creationTimestamp: "2025-01-09T14:58:21Z"
    labels:
      app.kubernetes.io/component: activator
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: release-v1.14
    managedFields:
    - apiVersion: autoscaling/v2
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubectl.kubernetes.io/last-applied-configuration: {}
            f:manifestival: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/version: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c"}: {}
        f:spec:
          f:maxReplicas: {}
          f:metrics: {}
          f:minReplicas: {}
          f:scaleTargetRef:
            f:apiVersion: {}
            f:kind: {}
            f:name: {}
      manager: manifestival
      operation: Update
      time: "2025-01-09T14:58:46Z"
    - apiVersion: autoscaling/v2
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"AbleToScale"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"ScalingActive"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"ScalingLimited"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:currentMetrics: {}
          f:currentReplicas: {}
          f:desiredReplicas: {}
          f:lastScaleTime: {}
      manager: kube-controller-manager
      operation: Update
      subresource: status
      time: "2025-01-09T15:01:22Z"
    name: activator
    namespace: knative-serving
    ownerReferences:
    - apiVersion: operator.knative.dev/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: KnativeServing
      name: knative-serving
      uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
    resourceVersion: "54715"
    uid: f7a05020-7e19-4c51-9be3-98bbd2490e06
  spec:
    maxReplicas: 21
    metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 100
          type: Utilization
      type: Resource
    minReplicas: 2
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: activator
  status:
    conditions:
    - lastTransitionTime: "2025-01-09T14:58:36Z"
      message: recommended size matches current size
      reason: ReadyForNewScale
      status: "True"
      type: AbleToScale
    - lastTransitionTime: "2025-01-09T14:59:21Z"
      message: the HPA was able to successfully calculate a replica count from cpu
        resource utilization (percentage of request)
      reason: ValidMetricFound
      status: "True"
      type: ScalingActive
    - lastTransitionTime: "2025-01-09T14:59:21Z"
      message: the desired replica count is less than the minimum replica count
      reason: TooFewReplicas
      status: "True"
      type: ScalingLimited
    currentMetrics:
    - resource:
        current:
          averageUtilization: 1
          averageValue: 4m
        name: cpu
      type: Resource
    currentReplicas: 2
    desiredReplicas: 2
    lastScaleTime: "2025-01-09T14:58:36Z"
- apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"autoscaling/v2","kind":"HorizontalPodAutoscaler","metadata":{"labels":{"app.kubernetes.io/component":"webhook","app.kubernetes.io/name":"knative-serving","app.kubernetes.io/version":"release-v1.14"},"name":"webhook","namespace":"knative-serving","ownerReferences":[{"apiVersion":"operator.knative.dev/v1beta1","blockOwnerDeletion":true,"controller":true,"kind":"KnativeServing","name":"knative-serving","uid":"aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c"}]},"spec":{"maxReplicas":6,"metrics":[{"resource":{"name":"cpu","target":{"averageUtilization":100,"type":"Utilization"}},"type":"Resource"}],"minReplicas":2,"scaleTargetRef":{"apiVersion":"apps/v1","kind":"Deployment","name":"webhook"}}}
      manifestival: new
    creationTimestamp: "2025-01-09T14:58:22Z"
    labels:
      app.kubernetes.io/component: webhook
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: release-v1.14
    managedFields:
    - apiVersion: autoscaling/v2
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:kubectl.kubernetes.io/last-applied-configuration: {}
            f:manifestival: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/component: {}
            f:app.kubernetes.io/name: {}
            f:app.kubernetes.io/version: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c"}: {}
        f:spec:
          f:maxReplicas: {}
          f:metrics: {}
          f:minReplicas: {}
          f:scaleTargetRef:
            f:apiVersion: {}
            f:kind: {}
            f:name: {}
      manager: manifestival
      operation: Update
      time: "2025-01-09T14:58:47Z"
    - apiVersion: autoscaling/v2
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"AbleToScale"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"ScalingActive"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"ScalingLimited"}:
              .: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:currentMetrics: {}
          f:currentReplicas: {}
          f:desiredReplicas: {}
          f:lastScaleTime: {}
      manager: kube-controller-manager
      operation: Update
      subresource: status
      time: "2025-01-09T15:10:53Z"
    name: webhook
    namespace: knative-serving
    ownerReferences:
    - apiVersion: operator.knative.dev/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: KnativeServing
      name: knative-serving
      uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
    resourceVersion: "60464"
    uid: e856d7c5-bbe0-437a-920c-dd06a01eeea5
  spec:
    maxReplicas: 6
    metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 100
          type: Utilization
      type: Resource
    minReplicas: 2
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: webhook
  status:
    conditions:
    - lastTransitionTime: "2025-01-09T14:58:37Z"
      message: recommended size matches current size
      reason: ReadyForNewScale
      status: "True"
      type: AbleToScale
    - lastTransitionTime: "2025-01-09T14:59:37Z"
      message: the HPA was able to successfully calculate a replica count from cpu
        resource utilization (percentage of request)
      reason: ValidMetricFound
      status: "True"
      type: ScalingActive
    - lastTransitionTime: "2025-01-09T14:59:37Z"
      message: the desired replica count is less than the minimum replica count
      reason: TooFewReplicas
      status: "True"
      type: ScalingLimited
    currentMetrics:
    - resource:
        current:
          averageUtilization: 2
          averageValue: 3m
        name: cpu
      type: Resource
    currentReplicas: 2
    desiredReplicas: 2
    lastScaleTime: "2025-01-09T14:58:37Z"
kind: HorizontalPodAutoscalerList
metadata:
  resourceVersion: "60707"
