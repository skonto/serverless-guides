---
apiVersion: v1
items:
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:22.122617Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51879"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/activator-57c5775dc-7v8qc to ip-10-0-118-213.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: activator-57c5775dc-7v8qc.18190e295bae26a3
    namespace: knative-serving
    resourceVersion: "51884"
    uid: b4c5d6be-1c8e-4a9b-add3-e5acf91bf1a2
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: 'MountVolume.SetUp failed for volume "secret-activator-sm-service-tls"
    : secret "activator-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: activator-57c5775dc-7v8qc.18190e2968611f7d
    namespace: knative-serving
    resourceVersion: "52029"
    uid: d7b55300-490b-4448-8fb5-d2e9ce1f84db
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51889"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Add eth0 [10.129.2.17/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: activator-57c5775dc-7v8qc.18190e2a571d12fd
    namespace: knative-serving
    resourceVersion: "52185"
    uid: 6d5e1d5b-bc69-4a89-8782-5f4fc32e1722
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-activator:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: activator-57c5775dc-7v8qc.18190e2a5fcaa148
    namespace: knative-serving
    resourceVersion: "52188"
    uid: 2fb6632d-d530-4705-b5e0-5bcbe4345276
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-activator:knative-v1.14"
    in 6.637s (6.637s including waiting). Image size: 159846640 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: activator-57c5775dc-7v8qc.18190e2beb6aa65c
    namespace: knative-serving
    resourceVersion: "52359"
    uid: 580a0aee-7afd-4e6b-8369-4864b4b13219
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container activator
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: activator-57c5775dc-7v8qc.18190e2bf3bd8842
    namespace: knative-serving
    resourceVersion: "52366"
    uid: d0d5344a-2379-46ba-9615-296863f8702d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container activator
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: activator-57c5775dc-7v8qc.18190e2bf4bd50f4
    namespace: knative-serving
    resourceVersion: "52372"
    uid: 9f7339b5-b521-48bd-bf24-22e05529dfce
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: activator-57c5775dc-7v8qc.18190e2bf4cbe4cb
    namespace: knative-serving
    resourceVersion: "52374"
    uid: 42b061af-1373-4695-8959-0c0439f13969
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 5.631s (5.631s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: activator-57c5775dc-7v8qc.18190e2d4477ec62
    namespace: knative-serving
    resourceVersion: "52538"
    uid: a698e1cc-b2f7-4959-8af8-e0b948f69a7c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: activator-57c5775dc-7v8qc.18190e2d4bef9392
    namespace: knative-serving
    resourceVersion: "52548"
    uid: 5bca4c4e-3253-4475-8836-74037aa0532d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: activator-57c5775dc-7v8qc.18190e2d4d062ed2
    namespace: knative-serving
    resourceVersion: "52553"
    uid: 0f2531b3-1614-4e8e-bfa8-9c8cbb1e3a2e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Container image "registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:4580f9a5da2c0ff7c881703095ab946b896f1703b6140c79091301648304cc37"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: activator-57c5775dc-7v8qc.18190e2d4d125b92
    namespace: knative-serving
    resourceVersion: "52554"
    uid: 97e0e743-8639-4bc4-acfb-3bec4733a4e8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Created container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: activator-57c5775dc-7v8qc.18190e2d536fe75a
    namespace: knative-serving
    resourceVersion: "52557"
    uid: 1ba60831-eb6c-4eaa-ace9-305973f5c6ac
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Started container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: activator-57c5775dc-7v8qc.18190e2d54723290
    namespace: knative-serving
    resourceVersion: "52559"
    uid: ceb957ec-dc87-44e5-9c43-4320ef26510e
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    resourceVersion: "51881"
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: 'Readiness probe failed: HTTP probe failed with statuscode: 500'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: activator-57c5775dc-7v8qc.18190e2db2576570
    namespace: knative-serving
    resourceVersion: "52668"
    uid: 05f40715-1548-48a6-8a1c-b8de60129109
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Warning
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:36.953202Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52482"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/activator-57c5775dc-zxbg9 to ip-10-0-63-72.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: activator-57c5775dc-zxbg9.18190e2ccfa7438c
    namespace: knative-serving
    resourceVersion: "52487"
    uid: a9c3c91b-01e9-4d74-94d8-447907db8f57
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:37Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:37Z"
  message: 'addLogicalPort failed for knative-serving/activator-57c5775dc-zxbg9: failed
    to update pod knative-serving/activator-57c5775dc-zxbg9: Operation cannot be fulfilled
    on pods "activator-57c5775dc-zxbg9": the object has been modified; please apply
    your changes to the latest version and try again'
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: ip-10-0-63-72
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: activator-57c5775dc-zxbg9.18190e2cd31f2b0e
    namespace: knative-serving
    resourceVersion: "52493"
    uid: 411c02d6-01f7-4623-b62c-a697c98ae4f1
  reason: ErrorUpdatingResource
  reportingComponent: controlplane
  reportingInstance: ""
  source:
    component: controlplane
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:37Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52494"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:37Z"
  message: Add eth0 [10.131.0.26/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: activator-57c5775dc-zxbg9.18190e2d0669311c
    namespace: knative-serving
    resourceVersion: "52509"
    uid: 9b08067b-766b-41bc-a640-564876167157
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-activator:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: activator-57c5775dc-zxbg9.18190e2d197d3a56
    namespace: knative-serving
    resourceVersion: "52530"
    uid: 1c9cdcce-e90e-4e9d-87a2-2a3bc547b5c0
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-activator:knative-v1.14"
    in 5.596s (5.596s including waiting). Image size: 159846640 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: activator-57c5775dc-zxbg9.18190e2e670a8225
    namespace: knative-serving
    resourceVersion: "52765"
    uid: 042ad5c6-048a-4a34-9cfd-23401272e9da
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Created container activator
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: activator-57c5775dc-zxbg9.18190e2e6de97801
    namespace: knative-serving
    resourceVersion: "52777"
    uid: a757d4ca-e2ed-475d-b445-bb1425695f81
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{activator}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Started container activator
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: activator-57c5775dc-zxbg9.18190e2e6ec5ad87
    namespace: knative-serving
    resourceVersion: "52778"
    uid: 7c4a7c03-85bc-4d3a-9509-c7da0bd6fcaa
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Container image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: activator-57c5775dc-zxbg9.18190e2e6ee744a7
    namespace: knative-serving
    resourceVersion: "52779"
    uid: 916f23d7-acdd-4643-b372-776d6703728e
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: activator-57c5775dc-zxbg9.18190e2e75025227
    namespace: knative-serving
    resourceVersion: "52785"
    uid: 83573fb4-d197-4a73-b45a-ac5e43d1bfa6
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: activator-57c5775dc-zxbg9.18190e2e75b8b8ec
    namespace: knative-serving
    resourceVersion: "52786"
    uid: 52b4f4dd-df08-4dfd-b3ed-ca67ff98a18c
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Pulling image "registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:4580f9a5da2c0ff7c881703095ab946b896f1703b6140c79091301648304cc37"
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: activator-57c5775dc-zxbg9.18190e2e75c291c4
    namespace: knative-serving
    resourceVersion: "52787"
    uid: 9c149da7-8f15-4a5d-959f-312c72c01205
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:55Z"
  message: 'Successfully pulled image "registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:4580f9a5da2c0ff7c881703095ab946b896f1703b6140c79091301648304cc37"
    in 11.61s (11.61s including waiting). Image size: 443521319 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:55Z"
    name: activator-57c5775dc-zxbg9.18190e3129cfa8c2
    namespace: knative-serving
    resourceVersion: "53043"
    uid: a418ab82-1c33-4df9-ad53-d42184592549
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:55Z"
  message: Created container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:55Z"
    name: activator-57c5775dc-zxbg9.18190e312fac3091
    namespace: knative-serving
    resourceVersion: "53045"
    uid: 51b8acb2-1555-4489-ac79-1c50d5548cd1
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:55Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    resourceVersion: "52483"
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:55Z"
  message: Started container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:55Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:55Z"
    name: activator-57c5775dc-zxbg9.18190e31307768e9
    namespace: knative-serving
    resourceVersion: "53046"
    uid: 9205d0a9-0926-4739-8186-0875d012cc75
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: activator-57c5775dc
    namespace: knative-serving
    resourceVersion: "51875"
    uid: 384167c1-12ac-4ca7-ad22-494968a9e648
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'Created pod: activator-57c5775dc-7v8qc'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: activator-57c5775dc.18190e295b3063d7
    namespace: knative-serving
    resourceVersion: "51880"
    uid: 5c53bfb3-268b-4cf6-94d0-a1578f6d1250
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: activator-57c5775dc
    namespace: knative-serving
    resourceVersion: "52477"
    uid: 384167c1-12ac-4ca7-ad22-494968a9e648
  kind: Event
  lastTimestamp: "2025-01-09T14:58:36Z"
  message: 'Created pod: activator-57c5775dc-zxbg9'
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: activator-57c5775dc.18190e2ccf06ac6f
    namespace: knative-serving
    resourceVersion: "52486"
    uid: 03a83452-84d4-49df-acc7-d1c6c8d6521d
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:21Z"
  involvedObject:
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    name: activator-pdb
    namespace: knative-serving
    resourceVersion: "51870"
    uid: 942430f4-7a87-4967-b92a-d48cbe483866
  kind: Event
  lastTimestamp: "2025-01-09T14:58:21Z"
  message: No matching pods found
  metadata:
    creationTimestamp: "2025-01-09T14:58:21Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:21Z"
    name: activator-pdb.18190e2950451ce7
    namespace: knative-serving
    resourceVersion: "51873"
    uid: 43c90f67-e033-4b90-8d68-8b35e48ebfca
  reason: NoPods
  reportingComponent: controllermanager
  reportingInstance: ""
  source:
    component: controllermanager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: activator
    namespace: knative-serving
    resourceVersion: "51874"
    uid: b3476dab-b562-43a7-b35c-341bcda2d74e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: Scaled up replica set activator-57c5775dc to 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: activator.18190e2958ecd0d8
    namespace: knative-serving
    resourceVersion: "51876"
    uid: 788c6d58-266b-4c4e-aa5c-61260097b0e1
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:36Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: activator
    namespace: knative-serving
    resourceVersion: "51869"
    uid: f7a05020-7e19-4c51-9be3-98bbd2490e06
  kind: Event
  lastTimestamp: "2025-01-09T14:58:36Z"
  message: 'New size: 2; reason: Current number of replicas below Spec.MinReplicas'
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: activator.18190e2cc8197198
    namespace: knative-serving
    resourceVersion: "52475"
    uid: 7faf31a0-57a1-4ec7-b8c8-d7caad3a697c
  reason: SuccessfulRescale
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:36Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: activator
    namespace: knative-serving
    resourceVersion: "52474"
    uid: b3476dab-b562-43a7-b35c-341bcda2d74e
  kind: Event
  lastTimestamp: "2025-01-09T14:58:36Z"
  message: Scaled up replica set activator-57c5775dc to 2 from 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: activator.18190e2cc8cb35e8
    namespace: knative-serving
    resourceVersion: "52478"
    uid: 38d1f980-5ec6-498b-9170-7128971bc2b0
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:51Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: activator
    namespace: knative-serving
    resourceVersion: "52874"
    uid: f7a05020-7e19-4c51-9be3-98bbd2490e06
  kind: Event
  lastTimestamp: "2025-01-09T14:59:06Z"
  message: 'failed to get cpu utilization: did not receive metrics for targeted pods
    (pods might be unready)'
  metadata:
    creationTimestamp: "2025-01-09T14:58:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:59:06Z"
    name: activator.18190e3047dfe596
    namespace: knative-serving
    resourceVersion: "53200"
    uid: c82a9fb4-3497-4a93-a5c4-ad99e67204ae
  reason: FailedGetResourceMetric
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:51Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: activator
    namespace: knative-serving
    resourceVersion: "52874"
    uid: f7a05020-7e19-4c51-9be3-98bbd2490e06
  kind: Event
  lastTimestamp: "2025-01-09T14:59:06Z"
  message: 'invalid metrics (1 invalid out of 1), first error is: failed to get cpu
    resource metric value: failed to get cpu utilization: did not receive metrics
    for targeted pods (pods might be unready)'
  metadata:
    creationTimestamp: "2025-01-09T14:58:51Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:59:06Z"
    name: activator.18190e3048421df6
    namespace: knative-serving
    resourceVersion: "53201"
    uid: 2fb3ac62-0d3d-4d92-bb11-1ff37b2849fd
  reason: FailedComputeMetricsReplicas
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Warning
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:22.436734Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51907"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/autoscaler-67654f944f-nkv26 to ip-10-0-118-213.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler-67654f944f-nkv26.18190e296e6731ac
    namespace: knative-serving
    resourceVersion: "51914"
    uid: 06a920b7-3d5e-4a61-aa0a-6b55632e6c50
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'addLogicalPort failed for knative-serving/autoscaler-67654f944f-nkv26:
    failed to update pod knative-serving/autoscaler-67654f944f-nkv26: Operation cannot
    be fulfilled on pods "autoscaler-67654f944f-nkv26": the object has been modified;
    please apply your changes to the latest version and try again'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: ip-10-0-118-213
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler-67654f944f-nkv26.18190e2972949cc1
    namespace: knative-serving
    resourceVersion: "51925"
    uid: 64622ae2-5d8b-4ceb-9161-e13cb993922e
  reason: ErrorUpdatingResource
  reportingComponent: controlplane
  reportingInstance: ""
  source:
    component: controlplane
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'MountVolume.SetUp failed for volume "secret-autoscaler-sm-service-tls"
    : secret "autoscaler-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: autoscaler-67654f944f-nkv26.18190e297463d2e0
    namespace: knative-serving
    resourceVersion: "52048"
    uid: 97d6eb45-e42b-447f-8d8a-710f23542868
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51926"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Add eth0 [10.129.2.19/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: autoscaler-67654f944f-nkv26.18190e2a6a76fbef
    namespace: knative-serving
    resourceVersion: "52192"
    uid: 6a00fb8d-fc80-40c1-bc1c-df5395ecb9e8
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-autoscaler:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: autoscaler-67654f944f-nkv26.18190e2a790319f9
    namespace: knative-serving
    resourceVersion: "52199"
    uid: aafe7f56-7f77-4655-9f7d-e9f4e89f0631
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-autoscaler:knative-v1.14"
    in 6.223s (6.223s including waiting). Image size: 160305401 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-67654f944f-nkv26.18190e2bebf17aa5
    namespace: knative-serving
    resourceVersion: "52361"
    uid: 97657f7c-b18f-4314-82f1-62d5af5d956a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container autoscaler
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-67654f944f-nkv26.18190e2bf44d733c
    namespace: knative-serving
    resourceVersion: "52369"
    uid: 5debb28f-3ffd-4908-a647-6aac5dd2e65d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container autoscaler
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-67654f944f-nkv26.18190e2bf58742b8
    namespace: knative-serving
    resourceVersion: "52376"
    uid: f48f71ba-a9cf-489c-b418-5a704883a1ae
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-67654f944f-nkv26.18190e2bf5908eee
    namespace: knative-serving
    resourceVersion: "52377"
    uid: e5cdd1d1-6a1d-44f8-b30e-446ab683b1b3
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 5.628s (5.628s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: autoscaler-67654f944f-nkv26.18190e2d45105c5a
    namespace: knative-serving
    resourceVersion: "52541"
    uid: b26c72d8-a995-44ee-805b-132b89015a9a
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: autoscaler-67654f944f-nkv26.18190e2d4c0440b2
    namespace: knative-serving
    resourceVersion: "52551"
    uid: 751452d6-830b-496e-ac13-26b8136abb95
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: autoscaler-67654f944f-nkv26.18190e2d4d2a958c
    namespace: knative-serving
    resourceVersion: "52555"
    uid: 05d9ab19-0948-4262-9110-f00d088bb1ac
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Container image "registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:4580f9a5da2c0ff7c881703095ab946b896f1703b6140c79091301648304cc37"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: autoscaler-67654f944f-nkv26.18190e2d4d442e59
    namespace: knative-serving
    resourceVersion: "52556"
    uid: 92296f37-04be-4a14-90d8-b3aec6b8018c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Created container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: autoscaler-67654f944f-nkv26.18190e2d53b0ccee
    namespace: knative-serving
    resourceVersion: "52558"
    uid: ffe34e05-a4a0-4d6a-b298-4489c23371a7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    resourceVersion: "51910"
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Started container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: autoscaler-67654f944f-nkv26.18190e2d549da172
    namespace: knative-serving
    resourceVersion: "52560"
    uid: 0da557f8-d8e3-43e5-9c76-5144e9c5b026
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:22.395246Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51902"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/autoscaler-67654f944f-s7bhw to ip-10-0-25-180.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler-67654f944f-s7bhw.18190e296bee27df
    namespace: knative-serving
    resourceVersion: "51905"
    uid: 4bc305a5-2a4e-4be3-8f61-30c51d110645
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'MountVolume.SetUp failed for volume "secret-autoscaler-sm-service-tls"
    : secret "autoscaler-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: autoscaler-67654f944f-s7bhw.18190e297ac3c648
    namespace: knative-serving
    resourceVersion: "52070"
    uid: e8e25900-de1b-457d-aa58-25aa4ec28f90
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51916"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Add eth0 [10.128.2.32/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: autoscaler-67654f944f-s7bhw.18190e2a680b5980
    namespace: knative-serving
    resourceVersion: "52191"
    uid: a2628962-d658-4edd-bbe8-bba96e516e16
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-autoscaler:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: autoscaler-67654f944f-s7bhw.18190e2a74888a5a
    namespace: knative-serving
    resourceVersion: "52196"
    uid: a8b2964a-6e77-4df4-99d7-11a7d8e4aa40
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:29Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:29Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-autoscaler:knative-v1.14"
    in 2.583s (2.583s including waiting). Image size: 160305401 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:29Z"
    name: autoscaler-67654f944f-s7bhw.18190e2b0e7f3736
    namespace: knative-serving
    resourceVersion: "52267"
    uid: 74ee1991-ab3f-4099-a614-a074ef170f4d
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:29Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:29Z"
  message: Created container autoscaler
  metadata:
    creationTimestamp: "2025-01-09T14:58:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:29Z"
    name: autoscaler-67654f944f-s7bhw.18190e2b14b37596
    namespace: knative-serving
    resourceVersion: "52270"
    uid: 41396d79-c648-4a14-8bb8-d7b02a79ea95
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:29Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:29Z"
  message: Started container autoscaler
  metadata:
    creationTimestamp: "2025-01-09T14:58:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:29Z"
    name: autoscaler-67654f944f-s7bhw.18190e2b15af537d
    namespace: knative-serving
    resourceVersion: "52272"
    uid: d4ac1a06-77da-4507-b871-32b9640b7daf
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:29Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:29Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:29Z"
    name: autoscaler-67654f944f-s7bhw.18190e2b15b91337
    namespace: knative-serving
    resourceVersion: "52273"
    uid: e4178fbc-24ec-41a1-b123-ee26fdbf2a05
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 10.639s (10.639s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d8fe77f1d
    namespace: knative-serving
    resourceVersion: "52594"
    uid: 2aa51c68-9395-4273-b571-0dd996f073a2
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d98017e77
    namespace: knative-serving
    resourceVersion: "52598"
    uid: 93c99ac0-6fe8-40d4-ab9d-a3cf02ae1d2a
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d99117f3d
    namespace: knative-serving
    resourceVersion: "52601"
    uid: 3b2b8b6f-124e-4456-a7fb-8801ffee9705
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Container image "registry.redhat.io/openshift-service-mesh/proxyv2-rhel8@sha256:4580f9a5da2c0ff7c881703095ab946b896f1703b6140c79091301648304cc37"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d991e7dfd
    namespace: knative-serving
    resourceVersion: "52602"
    uid: 38eb4bfa-c26e-45a7-8954-6b743e818697
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Created container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d9f01f518
    namespace: knative-serving
    resourceVersion: "52605"
    uid: 3e506bf6-eb11-4011-a256-1cb77a7dad02
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{istio-proxy}
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    resourceVersion: "51904"
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Started container istio-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-67654f944f-s7bhw.18190e2d9fb79377
    namespace: knative-serving
    resourceVersion: "52606"
    uid: cc2546f7-e798-4075-a488-6a6d4cc79155
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: autoscaler-67654f944f
    namespace: knative-serving
    resourceVersion: "51898"
    uid: c5d80ef8-7926-4fdf-96ff-c4d3f2eb2284
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'Created pod: autoscaler-67654f944f-s7bhw'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler-67654f944f.18190e296b5dc638
    namespace: knative-serving
    resourceVersion: "51903"
    uid: da700e6c-69cc-4869-8bfa-afeeda578f15
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: autoscaler-67654f944f
    namespace: knative-serving
    resourceVersion: "51898"
    uid: c5d80ef8-7926-4fdf-96ff-c4d3f2eb2284
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'Created pod: autoscaler-67654f944f-nkv26'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler-67654f944f.18190e296d95d7f6
    namespace: knative-serving
    resourceVersion: "51911"
    uid: fa335b91-39fb-4cd6-908a-4657693b266c
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:23.591106Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52000"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/autoscaler-hpa-597557bd7b-6dsl9 to
    ip-10-0-25-180.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e29b3358303
    namespace: knative-serving
    resourceVersion: "52004"
    uid: 2cf7a912-a18a-4228-83d6-d2e3e1ddeeff
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:25Z"
  message: 'MountVolume.SetUp failed for volume "secret-autoscaler-hpa-sm-service-tls"
    : secret "autoscaler-hpa-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:25Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e29c320b4f0
    namespace: knative-serving
    resourceVersion: "52150"
    uid: 0e869d0b-fad2-4739-a71b-ec092707a16b
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52007"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Add eth0 [10.128.2.33/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2aadebb24a
    namespace: knative-serving
    resourceVersion: "52229"
    uid: 6f819910-b005-4deb-aa1d-89ffd72f3b7c
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-autoscaler-hpa:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2aaf6b1cb5
    namespace: knative-serving
    resourceVersion: "52231"
    uid: 4a898a9b-47cc-4954-b604-0e57158f5153
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:31Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-autoscaler-hpa:knative-v1.14"
    in 3.299s (3.299s including waiting). Image size: 159160086 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:31Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2b7418d20c
    namespace: knative-serving
    resourceVersion: "52323"
    uid: fa0fa407-8b0a-4e41-bc30-2323e5ac86b8
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:31Z"
  message: Created container autoscaler-hpa
  metadata:
    creationTimestamp: "2025-01-09T14:58:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:31Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2b7a211e7d
    namespace: knative-serving
    resourceVersion: "52327"
    uid: ed0d4d24-09d1-48da-80cd-9bfac74b1949
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:31Z"
  message: Started container autoscaler-hpa
  metadata:
    creationTimestamp: "2025-01-09T14:58:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:31Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2b7af6ca10
    namespace: knative-serving
    resourceVersion: "52328"
    uid: 62f36031-3083-4634-96bc-6f12e103b6e3
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:31Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:31Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:31Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:31Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2b7b01f568
    namespace: knative-serving
    resourceVersion: "52329"
    uid: 49cb25b8-de6b-405b-b068-189db7942beb
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 8.966s (8.966s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2d9173efa9
    namespace: knative-serving
    resourceVersion: "52596"
    uid: 03eb221a-d070-4c82-81a9-502476cab699
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2d98ba194a
    namespace: knative-serving
    resourceVersion: "52600"
    uid: 6c0d2247-cd90-42be-9d5f-636608dd8cf5
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-6dsl9
    namespace: knative-serving
    resourceVersion: "52002"
    uid: 040cace3-d331-4749-bc09-dca9f74952d8
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: autoscaler-hpa-597557bd7b-6dsl9.18190e2d99f50a8e
    namespace: knative-serving
    resourceVersion: "52603"
    uid: 882f7588-6d28-4c45-8ba7-0d994af28ba0
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:23.625655Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52006"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/autoscaler-hpa-597557bd7b-9j47x to
    ip-10-0-83-16.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e29b544b0d9
    namespace: knative-serving
    resourceVersion: "52011"
    uid: cf0522fe-181b-46f0-b797-834c6f56d1a6
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:25Z"
  message: 'MountVolume.SetUp failed for volume "secret-autoscaler-hpa-sm-service-tls"
    : secret "autoscaler-hpa-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:25Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e29c35ffb89
    namespace: knative-serving
    resourceVersion: "52151"
    uid: 0d4007ae-5c96-403b-9871-a5e86d701ed1
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52014"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Add eth0 [10.130.2.23/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2ab50b5a88
    namespace: knative-serving
    resourceVersion: "52233"
    uid: 1320c893-be98-4cc8-80dd-3d20746f3480
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-autoscaler-hpa:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2ab68cb9be
    namespace: knative-serving
    resourceVersion: "52235"
    uid: 196d6ed9-7baf-4be5-93cd-33257a67e2e0
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-autoscaler-hpa:knative-v1.14"
    in 5.189s (5.189s including waiting). Image size: 159160086 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2bebdc532f
    namespace: knative-serving
    resourceVersion: "52360"
    uid: c6581f83-6724-4cc0-8b5f-9b0a5c77f4c1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container autoscaler-hpa
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2bf7a09f21
    namespace: knative-serving
    resourceVersion: "52379"
    uid: 303d9e03-4b70-4928-9945-7543153157a4
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{autoscaler-hpa}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container autoscaler-hpa
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2bf8aa87fb
    namespace: knative-serving
    resourceVersion: "52380"
    uid: 55fade18-eb18-4464-91b4-e5993986ce12
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2bf8b682ee
    namespace: knative-serving
    resourceVersion: "52381"
    uid: 581920a0-e0f0-405d-9e9e-3885ab6ade22
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 5.456s (5.456s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2d3df0cc9d
    namespace: knative-serving
    resourceVersion: "52536"
    uid: d46719ac-f542-4f08-a484-86dd03a90407
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2d44cb1e45
    namespace: knative-serving
    resourceVersion: "52539"
    uid: 64b99a0f-d076-4353-9d9e-0ee553ad0d03
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: autoscaler-hpa-597557bd7b-9j47x
    namespace: knative-serving
    resourceVersion: "52008"
    uid: b0c1ef12-1625-466d-af02-ad041aee2331
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: autoscaler-hpa-597557bd7b-9j47x.18190e2d45c9cde6
    namespace: knative-serving
    resourceVersion: "52542"
    uid: 8fab8ab1-287d-4435-a6d2-bac2aed3ce82
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: autoscaler-hpa-597557bd7b
    namespace: knative-serving
    resourceVersion: "51997"
    uid: 483c8d87-da5e-43ff-ae8c-a40e343367eb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: 'Created pod: autoscaler-hpa-597557bd7b-6dsl9'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: autoscaler-hpa-597557bd7b.18190e29b2c3d611
    namespace: knative-serving
    resourceVersion: "52003"
    uid: ecbc7a1a-d5bc-4c55-b80b-012112234b91
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: autoscaler-hpa-597557bd7b
    namespace: knative-serving
    resourceVersion: "51997"
    uid: 483c8d87-da5e-43ff-ae8c-a40e343367eb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: 'Created pod: autoscaler-hpa-597557bd7b-9j47x'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: autoscaler-hpa-597557bd7b.18190e29b4ed9496
    namespace: knative-serving
    resourceVersion: "52009"
    uid: 22c32a7a-505f-4d63-b2ba-60922345a8a3
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: autoscaler-hpa
    namespace: knative-serving
    resourceVersion: "51996"
    uid: 1c06e5f3-8bf4-4ccd-9ca6-09fc22dd3063
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: Scaled up replica set autoscaler-hpa-597557bd7b to 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: autoscaler-hpa.18190e29b12d48bf
    namespace: knative-serving
    resourceVersion: "51999"
    uid: 70be4abd-6538-46fa-a932-9e14bdce6ddf
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: autoscaler
    namespace: knative-serving
    resourceVersion: "51896"
    uid: 5db840e0-3b7a-401a-a0a3-a11ee551fe80
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: Scaled up replica set autoscaler-67654f944f to 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: autoscaler.18190e2968dc7c08
    namespace: knative-serving
    resourceVersion: "51899"
    uid: 06eb0dd8-f61f-45b4-818e-eca9a93d85c9
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:22.646711Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51937"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/controller-5cdf4475cb-mdk5g to ip-10-0-83-16.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: controller-5cdf4475cb-mdk5g.18190e297aeb306f
    namespace: knative-serving
    resourceVersion: "51944"
    uid: 19af681f-66db-4f6c-af13-afe1481652b4
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'MountVolume.SetUp failed for volume "secret-controller-sm-service-tls"
    : secret "controller-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: controller-5cdf4475cb-mdk5g.18190e2987451932
    namespace: knative-serving
    resourceVersion: "52096"
    uid: 011ffac0-a67c-4f79-aa58-48d89a12f6c3
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51948"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Add eth0 [10.130.2.22/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: controller-5cdf4475cb-mdk5g.18190e2a7cd638dc
    namespace: knative-serving
    resourceVersion: "52201"
    uid: 1a064a3b-b892-4b2f-a389-b7aa32e52a7d
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: controller-5cdf4475cb-mdk5g.18190e2a7f0cc867
    namespace: knative-serving
    resourceVersion: "52208"
    uid: 18e8f725-d6f2-4dc3-9bac-0b7e8c7464da
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
    in 6.122s (6.122s including waiting). Image size: 168792824 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: controller-5cdf4475cb-mdk5g.18190e2bebf3b557
    namespace: knative-serving
    resourceVersion: "52362"
    uid: d5acad35-b4c2-4fd6-b10f-7a07d19aa3fe
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: controller-5cdf4475cb-mdk5g.18190e2bf41fb6e5
    namespace: knative-serving
    resourceVersion: "52368"
    uid: a38d905a-082f-40e2-9aa3-a2774543d144
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: controller-5cdf4475cb-mdk5g.18190e2bf514dda8
    namespace: knative-serving
    resourceVersion: "52371"
    uid: 775c8d05-70b9-46e0-8fab-a1a2822f0e4d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: controller-5cdf4475cb-mdk5g.18190e2bf5206748
    namespace: knative-serving
    resourceVersion: "52373"
    uid: 4884883d-6b25-4f93-bd4f-0322921a346f
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 5.535s (5.535s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: controller-5cdf4475cb-mdk5g.18190e2d3f0d085b
    namespace: knative-serving
    resourceVersion: "52537"
    uid: f1a19210-fc0a-4dd0-b0b7-1c11a3e31ca6
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: controller-5cdf4475cb-mdk5g.18190e2d4558cdfa
    namespace: knative-serving
    resourceVersion: "52540"
    uid: a89fba17-791b-4c52-96ef-f1d63f39a4f3
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:38Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:38Z"
    name: controller-5cdf4475cb-mdk5g.18190e2d465a736d
    namespace: knative-serving
    resourceVersion: "52543"
    uid: e37e2547-3922-4526-9b31-fce09d1a3c1b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Stopping container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller-5cdf4475cb-mdk5g.18190e2ea5559c34
    namespace: knative-serving
    resourceVersion: "52824"
    uid: 9e774931-5562-4001-bab3-6b95cdc3e71e
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-mdk5g
    namespace: knative-serving
    resourceVersion: "51939"
    uid: e6dd1d4c-0f67-4134-9759-1890396c69f4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Stopping container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller-5cdf4475cb-mdk5g.18190e2ea55644ce
    namespace: knative-serving
    resourceVersion: "52831"
    uid: 6e977f00-1325-4d43-9e0f-5f26b30704da
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:22.629813Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51933"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/controller-5cdf4475cb-n97z7 to ip-10-0-63-72.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: controller-5cdf4475cb-n97z7.18190e2979e9534a
    namespace: knative-serving
    resourceVersion: "51938"
    uid: cd63a2d3-6a46-44ee-ae45-9d97839205c8
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'MountVolume.SetUp failed for volume "secret-controller-sm-service-tls"
    : secret "controller-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: controller-5cdf4475cb-n97z7.18190e298b28a9d6
    namespace: knative-serving
    resourceVersion: "52097"
    uid: f8ceeb77-cdaa-4a63-914c-8fa30222f646
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51947"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Add eth0 [10.131.0.21/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: controller-5cdf4475cb-n97z7.18190e2a7e582b39
    namespace: knative-serving
    resourceVersion: "52206"
    uid: adf29d63-67d1-447e-a9ed-2342b320a5c0
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: controller-5cdf4475cb-n97z7.18190e2a8e943ab2
    namespace: knative-serving
    resourceVersion: "52212"
    uid: fd02a881-8d8c-4ea5-b304-6b61128878e4
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
    in 8.374s (8.374s including waiting). Image size: 168792824 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: controller-5cdf4475cb-n97z7.18190e2c81be3035
    namespace: knative-serving
    resourceVersion: "52433"
    uid: 02fc1dd1-ff1e-4013-8adc-cb5bed2f46bc
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: controller-5cdf4475cb-n97z7.18190e2c8bda1550
    namespace: knative-serving
    resourceVersion: "52437"
    uid: e72f8d74-3414-4db7-b295-536e6fee6b17
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: controller-5cdf4475cb-n97z7.18190e2c8d0fa872
    namespace: knative-serving
    resourceVersion: "52440"
    uid: fa10e9d4-c73b-44d8-80c1-dcfa844fa71b
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: controller-5cdf4475cb-n97z7.18190e2c8d1b42cb
    namespace: knative-serving
    resourceVersion: "52441"
    uid: e57d172d-68c6-4de6-acfa-095274d9622b
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 7.967s (7.967s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-5cdf4475cb-n97z7.18190e2e680564e0
    namespace: knative-serving
    resourceVersion: "52771"
    uid: f03506d2-aff6-46b2-bf2e-4dcdcf2cc603
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-5cdf4475cb-n97z7.18190e2e6ef9331e
    namespace: knative-serving
    resourceVersion: "52780"
    uid: b599a441-75ef-4fa9-b538-037135cd5aa7
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-5cdf4475cb-n97z7.18190e2e7008c39d
    namespace: knative-serving
    resourceVersion: "52782"
    uid: c804e1a1-05f8-41ba-a603-9a0edf6cd256
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Stopping container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller-5cdf4475cb-n97z7.18190e2e8d013ea1
    namespace: knative-serving
    resourceVersion: "52793"
    uid: 9697a819-989f-4ec4-acb6-89609177ab8a
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-5cdf4475cb-n97z7
    namespace: knative-serving
    resourceVersion: "51935"
    uid: e6f151a5-0e61-499b-b332-5523fc150c35
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Stopping container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller-5cdf4475cb-n97z7.18190e2e8d0341e0
    namespace: knative-serving
    resourceVersion: "52794"
    uid: 5329a2c8-cf73-4715-8c38-cdb9e1a7b384
  reason: Killing
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-5cdf4475cb
    namespace: knative-serving
    resourceVersion: "51930"
    uid: 48adb90a-ac21-499d-bcc9-20366442e3ec
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'Created pod: controller-5cdf4475cb-n97z7'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: controller-5cdf4475cb.18190e29796cd9df
    namespace: knative-serving
    resourceVersion: "51934"
    uid: 299516ff-b76f-445f-9ba9-3b067a4379d6
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-5cdf4475cb
    namespace: knative-serving
    resourceVersion: "51930"
    uid: 48adb90a-ac21-499d-bcc9-20366442e3ec
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: 'Created pod: controller-5cdf4475cb-mdk5g'
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: controller-5cdf4475cb.18190e297a78444d
    namespace: knative-serving
    resourceVersion: "51940"
    uid: 703ab5ab-f78e-4f3e-a6dc-7bf6c7c60392
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-5cdf4475cb
    namespace: knative-serving
    resourceVersion: "52639"
    uid: 48adb90a-ac21-499d-bcc9-20366442e3ec
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: 'Deleted pod: controller-5cdf4475cb-n97z7'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-5cdf4475cb.18190e2db8a763e6
    namespace: knative-serving
    resourceVersion: "52643"
    uid: 6d8cac16-b0fc-4aae-ada6-52b36bbaa6a3
  reason: SuccessfulDelete
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-5cdf4475cb
    namespace: knative-serving
    resourceVersion: "52820"
    uid: 48adb90a-ac21-499d-bcc9-20366442e3ec
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: 'Deleted pod: controller-5cdf4475cb-mdk5g'
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller-5cdf4475cb.18190e2ea533ade6
    namespace: knative-serving
    resourceVersion: "52829"
    uid: c3131a82-42e7-4866-bf65-162d28ee41ad
  reason: SuccessfulDelete
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:24.006124Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52038"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/controller-84d56ccfc4-ffm5k to ip-10-0-25-180.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: controller-84d56ccfc4-ffm5k.18190e29cbf231b4
    namespace: knative-serving
    resourceVersion: "52040"
    uid: a55ec91f-a0b7-4fbd-817e-8991c74b7432
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:25Z"
  message: 'MountVolume.SetUp failed for volume "secret-controller-sm-service-tls"
    : secret "controller-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:25Z"
    name: controller-84d56ccfc4-ffm5k.18190e29d4ff6588
    namespace: knative-serving
    resourceVersion: "52165"
    uid: ac4903e8-49b2-41ec-8f99-a10ef0b6b9c1
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:28Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52045"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:28Z"
  message: Add eth0 [10.128.2.35/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:28Z"
    name: controller-84d56ccfc4-ffm5k.18190e2ac6b9105f
    namespace: knative-serving
    resourceVersion: "52239"
    uid: 378fc480-b159-4f8d-9a4a-acfcf769191c
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:28Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:28Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:28Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:28Z"
    name: controller-84d56ccfc4-ffm5k.18190e2ac81fcd20
    namespace: knative-serving
    resourceVersion: "52241"
    uid: e5794a95-3497-419b-8643-3682ee2b449b
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:30Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
    in 2.379s (2.379s including waiting). Image size: 168792824 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:30Z"
    name: controller-84d56ccfc4-ffm5k.18190e2b55ef6d8e
    namespace: knative-serving
    resourceVersion: "52296"
    uid: b310bf37-ffe7-4558-9438-0e5539fa3086
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:30Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:30Z"
    name: controller-84d56ccfc4-ffm5k.18190e2b5c02576a
    namespace: knative-serving
    resourceVersion: "52298"
    uid: de09b9da-57f6-426f-92cf-4a1ee75c4b0e
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:30Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:30Z"
    name: controller-84d56ccfc4-ffm5k.18190e2b5cc91dd8
    namespace: knative-serving
    resourceVersion: "52299"
    uid: 31cb7fff-9bb2-4fe4-b185-c2f7a0d0d6d5
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:30Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:30Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:30Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:30Z"
    name: controller-84d56ccfc4-ffm5k.18190e2b5cd3cdc8
    namespace: knative-serving
    resourceVersion: "52300"
    uid: db80c176-d1e2-4760-8db8-f8ae3c61b59b
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 9.416s (9.416s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-84d56ccfc4-ffm5k.18190e2d8e138faa
    namespace: knative-serving
    resourceVersion: "52593"
    uid: c110197e-7a11-4b6c-b785-fd92eb0f6b92
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-84d56ccfc4-ffm5k.18190e2d9781436d
    namespace: knative-serving
    resourceVersion: "52597"
    uid: 75d46483-2210-4d29-b3e9-d8505486e56d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-ffm5k
    namespace: knative-serving
    resourceVersion: "52039"
    uid: c9e628d4-9b10-4996-b5b3-6cfb7b60faa0
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-84d56ccfc4-ffm5k.18190e2d98683330
    namespace: knative-serving
    resourceVersion: "52599"
    uid: 163adc71-289c-498c-9ae1-c406019e7ee8
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:40.915302Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52648"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/controller-84d56ccfc4-q2kkb to ip-10-0-118-213.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-84d56ccfc4-q2kkb.18190e2dbbcfbe24
    namespace: knative-serving
    resourceVersion: "52658"
    uid: 1f79e7c6-54cd-4f69-a3e3-fe0ff827f862
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52664"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Add eth0 [10.129.2.21/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: controller-84d56ccfc4-q2kkb.18190e2de0cd7758
    namespace: knative-serving
    resourceVersion: "52689"
    uid: ded009b5-6483-48f1-a40e-323e9ba1fefc
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: controller-84d56ccfc4-q2kkb.18190e2de24921ce
    namespace: knative-serving
    resourceVersion: "52692"
    uid: 96f3959a-d6c0-42a8-b750-66ab026a9306
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-controller:knative-v1.14"
    in 1.866s (1.866s including waiting). Image size: 168792824 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e518f957b
    namespace: knative-serving
    resourceVersion: "52751"
    uid: c31ca0be-71fd-45c3-bad7-61a597c45ec1
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e576feca3
    namespace: knative-serving
    resourceVersion: "52752"
    uid: 39d5a3a6-9ee4-405a-9fc0-9c8cf19ff12c
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e58419825
    namespace: knative-serving
    resourceVersion: "52753"
    uid: 367dfa18-91f3-4189-8c41-304a97982723
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Container image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e58623336
    namespace: knative-serving
    resourceVersion: "52754"
    uid: 204efcad-7bde-4e05-b398-109fc5b58c53
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e5f46f9e9
    namespace: knative-serving
    resourceVersion: "52759"
    uid: 0f73155e-49c8-44f5-ba7b-7e92adce1598
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e6038fad5
    namespace: knative-serving
    resourceVersion: "52760"
    uid: 419d1804-0588-4252-9e4d-b067a215747d
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: controller-84d56ccfc4-q2kkb
    namespace: knative-serving
    resourceVersion: "52652"
    uid: a4582568-aaac-48a0-938f-f5f3d22b895a
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: 'Readiness probe failed: Get "http://10.129.2.21:8080/readiness": dial
    tcp 10.129.2.21:8080: connect: connection refused'
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: controller-84d56ccfc4-q2kkb.18190e2e65a1bd12
    namespace: knative-serving
    resourceVersion: "52762"
    uid: 5be12a9d-d3be-4c92-b5c1-e925fdaf70b8
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-84d56ccfc4
    namespace: knative-serving
    resourceVersion: "52035"
    uid: 95f60c80-ec04-4ceb-b940-76abc7f89699
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'Created pod: controller-84d56ccfc4-ffm5k'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: controller-84d56ccfc4.18190e29cc183289
    namespace: knative-serving
    resourceVersion: "52042"
    uid: c0160d31-cc1a-478e-b135-8a33c394276a
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: controller-84d56ccfc4
    namespace: knative-serving
    resourceVersion: "52645"
    uid: 95f60c80-ec04-4ceb-b940-76abc7f89699
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: 'Created pod: controller-84d56ccfc4-q2kkb'
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller-84d56ccfc4.18190e2dbac3934a
    namespace: knative-serving
    resourceVersion: "52655"
    uid: 3bc04f86-858d-44f2-aee8-99c59ab84983
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: controller
    namespace: knative-serving
    resourceVersion: "51929"
    uid: 46eaefd9-7166-4603-9ec6-6667d71f999b
  kind: Event
  lastTimestamp: "2025-01-09T14:58:22Z"
  message: Scaled up replica set controller-5cdf4475cb to 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:22Z"
    name: controller.18190e2978a63280
    namespace: knative-serving
    resourceVersion: "51931"
    uid: f9057e86-4299-40ea-b95b-6a10ffecf37c
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: controller
    namespace: knative-serving
    resourceVersion: "52034"
    uid: 46eaefd9-7166-4603-9ec6-6667d71f999b
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: Scaled up replica set controller-84d56ccfc4 to 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: controller.18190e29c9e04be1
    namespace: knative-serving
    resourceVersion: "52036"
    uid: 1bb96a8b-b3de-4e35-b1dc-6059bbd55eb7
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: controller
    namespace: knative-serving
    resourceVersion: "52050"
    uid: 46eaefd9-7166-4603-9ec6-6667d71f999b
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Scaled down replica set controller-5cdf4475cb to 1 from 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller.18190e2db83a13d0
    namespace: knative-serving
    resourceVersion: "52641"
    uid: 24c3f28a-6bf9-431e-a717-22894ad6e583
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:40Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: controller
    namespace: knative-serving
    resourceVersion: "52050"
    uid: 46eaefd9-7166-4603-9ec6-6667d71f999b
  kind: Event
  lastTimestamp: "2025-01-09T14:58:40Z"
  message: Scaled up replica set controller-84d56ccfc4 to 2 from 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:40Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:40Z"
    name: controller.18190e2db9a339ce
    namespace: knative-serving
    resourceVersion: "52647"
    uid: 63f4ae58-c416-4783-87dc-8319209070df
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:44Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: controller
    namespace: knative-serving
    resourceVersion: "52663"
    uid: 46eaefd9-7166-4603-9ec6-6667d71f999b
  kind: Event
  lastTimestamp: "2025-01-09T14:58:44Z"
  message: Scaled down replica set controller-5cdf4475cb to 0 from 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:44Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:44Z"
    name: controller.18190e2ea44da8c4
    namespace: knative-serving
    resourceVersion: "52821"
    uid: daa3c56d-434a-4850-9001-a065be0ede55
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- action: IPTablesUsageObserved
  apiVersion: v1
  eventTime: "2025-01-09T15:03:04.405960Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-s7bhw
    namespace: knative-serving
    uid: 60792f44-3955-40fc-abfc-b66c6debd173
  kind: Event
  lastTimestamp: null
  message: |
    This pod appears to have created one or more iptables rules. IPTables is
    deprecated and will no longer be available in RHEL 10 and later. You should
    consider migrating to another API such as nftables or eBPF. See also
    https://access.redhat.com/solutions/6739041

    Example iptables rule seen in this pod:
    -A PREROUTING -p udp -m udp --sport 53 -j CT --zone 1
  metadata:
    creationTimestamp: "2025-01-09T15:03:21Z"
    generateName: iptables-alert-
    labels:
      pod-uid: 60792f44-3955-40fc-abfc-b66c6debd173
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:pod-uid: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kubectl-create
      operation: Update
      time: "2025-01-09T15:03:21Z"
    name: iptables-alert-fjvnh
    namespace: knative-serving
    resourceVersion: "55946"
    uid: f06a46b8-e832-4c5e-8b48-9e3a8c788cb6
  reason: IPTablesUsageObserved
  reportingComponent: openshift.io/iptables-deprecation-alerter
  reportingInstance: iptables-alerter-4hsnz
  source: {}
  type: Normal
- action: IPTablesUsageObserved
  apiVersion: v1
  eventTime: "2025-01-09T14:59:47.376872Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-zxbg9
    namespace: knative-serving
    uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
  kind: Event
  lastTimestamp: null
  message: |
    This pod appears to have created one or more iptables rules. IPTables is
    deprecated and will no longer be available in RHEL 10 and later. You should
    consider migrating to another API such as nftables or eBPF. See also
    https://access.redhat.com/solutions/6739041

    Example iptables rule seen in this pod:
    -A PREROUTING -p udp -m udp --sport 53 -j CT --zone 1
  metadata:
    creationTimestamp: "2025-01-09T15:00:05Z"
    generateName: iptables-alert-
    labels:
      pod-uid: 4451f417-1bf7-4d73-a4c7-a66cac153e4e
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:pod-uid: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kubectl-create
      operation: Update
      time: "2025-01-09T15:00:05Z"
    name: iptables-alert-mj4jk
    namespace: knative-serving
    resourceVersion: "53946"
    uid: 24c58bf3-8b78-49ea-8aa1-878a6ea0f9b2
  reason: IPTablesUsageObserved
  reportingComponent: openshift.io/iptables-deprecation-alerter
  reportingInstance: iptables-alerter-mqbjq
  source: {}
  type: Normal
- action: IPTablesUsageObserved
  apiVersion: v1
  eventTime: "2025-01-09T15:01:32.257707Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: autoscaler-67654f944f-nkv26
    namespace: knative-serving
    uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
  kind: Event
  lastTimestamp: null
  message: |
    This pod appears to have created one or more iptables rules. IPTables is
    deprecated and will no longer be available in RHEL 10 and later. You should
    consider migrating to another API such as nftables or eBPF. See also
    https://access.redhat.com/solutions/6739041

    Example iptables rule seen in this pod:
    -A PREROUTING -p udp -m udp --sport 53 -j CT --zone 1
  metadata:
    creationTimestamp: "2025-01-09T15:01:46Z"
    generateName: iptables-alert-
    labels:
      pod-uid: acbd9c52-c1e0-41ae-a814-f556f0e33d87
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:pod-uid: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kubectl-create
      operation: Update
      time: "2025-01-09T15:01:46Z"
    name: iptables-alert-n2lb8
    namespace: knative-serving
    resourceVersion: "54971"
    uid: 15638ad2-37e9-46f1-9192-62cc7aa671c7
  reason: IPTablesUsageObserved
  reportingComponent: openshift.io/iptables-deprecation-alerter
  reportingInstance: iptables-alerter-sc7bj
  source: {}
  type: Normal
- action: IPTablesUsageObserved
  apiVersion: v1
  eventTime: "2025-01-09T15:02:24.758397Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: activator-57c5775dc-7v8qc
    namespace: knative-serving
    uid: f95cda82-b938-4d88-8497-01e28db3d2b7
  kind: Event
  lastTimestamp: null
  message: |
    This pod appears to have created one or more iptables rules. IPTables is
    deprecated and will no longer be available in RHEL 10 and later. You should
    consider migrating to another API such as nftables or eBPF. See also
    https://access.redhat.com/solutions/6739041

    Example iptables rule seen in this pod:
    -A PREROUTING -p udp -m udp --sport 53 -j CT --zone 1
  metadata:
    creationTimestamp: "2025-01-09T15:02:39Z"
    generateName: iptables-alert-
    labels:
      pod-uid: f95cda82-b938-4d88-8497-01e28db3d2b7
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:metadata:
          f:generateName: {}
          f:labels:
            .: {}
            f:pod-uid: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kubectl-create
      operation: Update
      time: "2025-01-09T15:02:39Z"
    name: iptables-alert-tb5x9
    namespace: knative-serving
    resourceVersion: "55515"
    uid: c65cecd9-223b-4f0a-ba8f-00e85a437216
  reason: IPTablesUsageObserved
  reportingComponent: openshift.io/iptables-deprecation-alerter
  reportingInstance: iptables-alerter-sc7bj
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:14Z"
  involvedObject:
    apiVersion: operator.knative.dev/v1beta1
    kind: KnativeServing
    name: knative-serving
    namespace: knative-serving
    resourceVersion: "51598"
    uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:14Z"
  message: 'Failed to update finalizers for "knative-serving": Operation cannot be
    fulfilled on knativeservings.operator.knative.dev "knative-serving": the object
    has been modified; please apply your changes to the latest version and try again'
  metadata:
    creationTimestamp: "2025-01-09T14:58:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: openshift-knative-operator
      operation: Update
      time: "2025-01-09T14:58:14Z"
    name: knative-serving.18190e27a905dc5f
    namespace: knative-serving
    resourceVersion: "51601"
    uid: 3a5438bf-2696-478a-a0ad-fbab9a35993e
  reason: FinalizerUpdateFailed
  reportingComponent: knativeserving-controller
  reportingInstance: ""
  source:
    component: knativeserving-controller
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:14Z"
  involvedObject:
    apiVersion: operator.knative.dev/v1beta1
    kind: KnativeServing
    name: knative-serving
    namespace: knative-serving
    resourceVersion: "51604"
    uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:14Z"
  message: Updated "knative-serving" finalizers
  metadata:
    creationTimestamp: "2025-01-09T14:58:14Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: openshift-knative-operator
      operation: Update
      time: "2025-01-09T14:58:14Z"
    name: knative-serving.18190e27aa4159b8
    namespace: knative-serving
    resourceVersion: "51608"
    uid: 8168e8a6-9f11-4a6a-9c44-0e31ff25eb73
  reason: FinalizerUpdate
  reportingComponent: knativeserving-controller
  reportingInstance: ""
  source:
    component: knativeserving-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:32Z"
  involvedObject:
    apiVersion: operator.knative.dev/v1beta1
    kind: KnativeServing
    name: knative-serving
    namespace: knative-serving
    resourceVersion: "52220"
    uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: 'failed to apply non rbac manifest: Internal error occurred: failed calling
    webhook "webhook.serving.knative.dev": failed to call webhook: Post "https://webhook.knative-serving.svc:443/?timeout=10s":
    no endpoints available for service "webhook"'
  metadata:
    creationTimestamp: "2025-01-09T14:58:32Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: openshift-knative-operator
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: knative-serving.18190e2bacd39174
    namespace: knative-serving
    resourceVersion: "52429"
    uid: 51a06327-7e73-47fc-b413-52a38f42f744
  reason: InternalError
  reportingComponent: knativeserving-controller
  reportingInstance: ""
  source:
    component: knativeserving-controller
  type: Warning
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:38Z"
  involvedObject:
    apiVersion: operator.knative.dev/v1beta1
    kind: KnativeServing
    name: knative-serving
    namespace: knative-serving
    resourceVersion: "52344"
    uid: aed016d4-b7c0-4f05-ace9-ef4eec4aeb9c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: 'failed to apply non rbac manifest: Internal error occurred: failed calling
    webhook "webhook.serving.knative.dev": failed to call webhook: Post "https://webhook.knative-serving.svc:443/defaulting?timeout=10s":
    no endpoints available for service "webhook"'
  metadata:
    creationTimestamp: "2025-01-09T14:58:38Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: openshift-knative-operator
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: knative-serving.18190e2d12c57dff
    namespace: knative-serving
    resourceVersion: "52670"
    uid: d46301f8-94e3-48c1-ab40-21d0be7a259f
  reason: InternalError
  reportingComponent: knativeserving-controller
  reportingInstance: ""
  source:
    component: knativeserving-controller
  type: Warning
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:24.115277Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52054"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/net-istio-controller-7f99bfd446-76xqm
    to ip-10-0-63-72.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e29d273ca15
    namespace: knative-serving
    resourceVersion: "52057"
    uid: fa61f32f-0ab7-4cf4-b67a-03adee55c88c
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52069"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Add eth0 [10.131.0.23/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e29f7303271
    namespace: knative-serving
    resourceVersion: "52112"
    uid: 2ca58742-e89f-4851-8d87-51100e818d78
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52055"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Pulling image "registry.ci.openshift.org/openshift/net-istio-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e29f8a80001
    namespace: knative-serving
    resourceVersion: "52115"
    uid: c7acfe13-ec24-4974-8b72-d1e421a3dcf8
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52055"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/net-istio-controller:knative-v1.14"
    in 10.918s (10.918s including waiting). Image size: 524385802 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e2c836f28c4
    namespace: knative-serving
    resourceVersion: "52434"
    uid: 817a9dbc-d5ef-4ca1-b6bc-5be9d0dd32d0
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52055"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e2c9101603b
    namespace: knative-serving
    resourceVersion: "52442"
    uid: 64f24d5f-b371-4a8a-8a1a-4c4b47913c0b
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52055"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e2c920a3978
    namespace: knative-serving
    resourceVersion: "52443"
    uid: 25e5592a-603a-405f-aff8-67d0ff0dc2b2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-76xqm
    namespace: knative-serving
    resourceVersion: "52055"
    uid: 055a8b9b-8bc0-492d-8eb5-35ad0d6e69f6
  kind: Event
  lastTimestamp: "2025-01-09T14:58:36Z"
  message: 'Readiness probe failed: Get "http://10.131.0.23:8080/readiness": dial
    tcp 10.131.0.23:8080: connect: connection refused'
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: net-istio-controller-7f99bfd446-76xqm.18190e2cae365d53
    namespace: knative-serving
    resourceVersion: "52464"
    uid: 4ed5dd17-89b9-44a9-b9c4-274f8cbb2783
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Warning
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:24.143282Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52059"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/net-istio-controller-7f99bfd446-qnvk9
    to ip-10-0-83-16.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e29d41f15dc
    namespace: knative-serving
    resourceVersion: "52065"
    uid: ede8ff99-fcac-4ba7-bc12-0da42f01d2d8
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52066"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Add eth0 [10.130.2.24/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e29f8460380
    namespace: knative-serving
    resourceVersion: "52114"
    uid: 282729cd-da49-44dd-95ec-5232486a967b
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52061"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Pulling image "registry.ci.openshift.org/openshift/net-istio-controller:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e29f99851dd
    namespace: knative-serving
    resourceVersion: "52117"
    uid: ca3490c1-8c3e-4c7a-a9b8-9b5d15f572e7
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52061"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/net-istio-controller:knative-v1.14"
    in 8.446s (8.446s including waiting). Image size: 524385802 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e2bf10acde9
    namespace: knative-serving
    resourceVersion: "52365"
    uid: 4230ec3b-8c28-4aa0-a403-f8febd97190f
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52061"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e2bfd9448f1
    namespace: knative-serving
    resourceVersion: "52385"
    uid: ac5014f6-164f-4d4a-835f-82e7bca31056
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52061"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container controller
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e2bfe9c2e54
    namespace: knative-serving
    resourceVersion: "52386"
    uid: ca5ca095-bf93-447a-ad23-93103d8a2ec4
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{controller}
    kind: Pod
    name: net-istio-controller-7f99bfd446-qnvk9
    namespace: knative-serving
    resourceVersion: "52061"
    uid: 23f28cec-5915-413c-b369-ab34e2bbe04f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Readiness probe failed: Get "http://10.130.2.24:8080/readiness": dial
    tcp 10.130.2.24:8080: connect: connection refused'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-controller-7f99bfd446-qnvk9.18190e2c1623cba0
    namespace: knative-serving
    resourceVersion: "52401"
    uid: d3af351e-63f2-434a-a4ac-6609cd59a7f8
  reason: Unhealthy
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: net-istio-controller-7f99bfd446
    namespace: knative-serving
    resourceVersion: "52051"
    uid: 9d1e7410-28ed-4afe-bb08-b2b4c6d909ef
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'Created pod: net-istio-controller-7f99bfd446-76xqm'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446.18190e29d1f81fdb
    namespace: knative-serving
    resourceVersion: "52056"
    uid: 6f7d4bea-8dd3-45c4-b742-12eb24747179
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: net-istio-controller-7f99bfd446
    namespace: knative-serving
    resourceVersion: "52051"
    uid: 9d1e7410-28ed-4afe-bb08-b2b4c6d909ef
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'Created pod: net-istio-controller-7f99bfd446-qnvk9'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller-7f99bfd446.18190e29d3ad6e58
    namespace: knative-serving
    resourceVersion: "52062"
    uid: 59e47ae8-f273-4c74-9644-c5104179a5ab
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: net-istio-controller
    namespace: knative-serving
    resourceVersion: "52049"
    uid: c4baf693-cbc2-447a-91d1-3a686348ea63
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Scaled up replica set net-istio-controller-7f99bfd446 to 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-controller.18190e29d0c976a0
    namespace: knative-serving
    resourceVersion: "52053"
    uid: 7088ba1f-ffc9-4112-a60a-84f88c014632
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:24.236707Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52076"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/net-istio-webhook-5fbccdd7d5-6n9c9
    to ip-10-0-63-72.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e29d9b09bcc
    namespace: knative-serving
    resourceVersion: "52080"
    uid: 19695c70-8687-4160-a0e3-28549d95b021
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:25Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52089"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:25Z"
  message: Add eth0 [10.131.0.24/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:25Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e2a10142996
    namespace: knative-serving
    resourceVersion: "52144"
    uid: cd5dc79e-a4d1-49e2-8842-913c60ea295f
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:25Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52077"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:25Z"
  message: Pulling image "registry.ci.openshift.org/openshift/net-istio-webhook:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:25Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:25Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e2a123f24b1
    namespace: knative-serving
    resourceVersion: "52146"
    uid: 9c879958-05b3-474f-8e88-0f33e0702a1e
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52077"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/net-istio-webhook:knative-v1.14"
    in 10.49s (10.49s including waiting). Image size: 521743346 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e2c838dfac5
    namespace: knative-serving
    resourceVersion: "52435"
    uid: 9cc2281c-b14e-4095-b6a6-d8f7b6588ee5
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52077"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Created container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e2c960ea1d4
    namespace: knative-serving
    resourceVersion: "52444"
    uid: cc979dc1-c32b-432d-9f74-69e1a43b495d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:36Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6n9c9
    namespace: knative-serving
    resourceVersion: "52077"
    uid: 015d5af4-2016-4565-9b6b-6c5fee8a5edb
  kind: Event
  lastTimestamp: "2025-01-09T14:58:36Z"
  message: Started container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:36Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:36Z"
    name: net-istio-webhook-5fbccdd7d5-6n9c9.18190e2c96efbc0b
    namespace: knative-serving
    resourceVersion: "52446"
    uid: 30499dd6-7e5f-4265-bb32-cf2e317f3172
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:24.258073Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52081"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/net-istio-webhook-5fbccdd7d5-6wpfd
    to ip-10-0-118-213.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e29daf69f96
    namespace: knative-serving
    resourceVersion: "52086"
    uid: d90de23e-dfbc-41e8-9d1f-28990ff30ecf
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52091"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Add eth0 [10.129.2.20/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e29fff2ba8e
    namespace: knative-serving
    resourceVersion: "52124"
    uid: 1e4660f5-2867-4339-881f-67ba1a077633
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52083"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Pulling image "registry.ci.openshift.org/openshift/net-istio-webhook:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e2a021b02fe
    namespace: knative-serving
    resourceVersion: "52126"
    uid: a7b31697-8da9-4fac-a3d0-4ee0eb579320
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52083"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/net-istio-webhook:knative-v1.14"
    in 8.278s (8.278s including waiting). Image size: 521743346 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e2bef8685e9
    namespace: knative-serving
    resourceVersion: "52364"
    uid: 88a89704-2feb-4ce1-bd88-eb852a369f1c
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52083"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Created container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e2bfadc4fc2
    namespace: knative-serving
    resourceVersion: "52383"
    uid: f079576d-f372-40b2-a8d6-8ec831ad7ce6
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:33Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: net-istio-webhook-5fbccdd7d5-6wpfd
    namespace: knative-serving
    resourceVersion: "52083"
    uid: 6bdcf05a-17e3-4935-93e5-992d69a8e448
  kind: Event
  lastTimestamp: "2025-01-09T14:58:33Z"
  message: Started container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:33Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:33Z"
    name: net-istio-webhook-5fbccdd7d5-6wpfd.18190e2bfba41241
    namespace: knative-serving
    resourceVersion: "52384"
    uid: 0babbe79-5db7-4c27-be34-3e3b1d8fe623
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-118-213.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-118-213.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: net-istio-webhook-5fbccdd7d5
    namespace: knative-serving
    resourceVersion: "52073"
    uid: b6180cb8-c555-4e53-bc12-eff72229c80f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'Created pod: net-istio-webhook-5fbccdd7d5-6n9c9'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5.18190e29d957c3db
    namespace: knative-serving
    resourceVersion: "52078"
    uid: 699eb26b-6eb1-42da-94cd-14aa3221048b
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: net-istio-webhook-5fbccdd7d5
    namespace: knative-serving
    resourceVersion: "52073"
    uid: b6180cb8-c555-4e53-bc12-eff72229c80f
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'Created pod: net-istio-webhook-5fbccdd7d5-6wpfd'
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook-5fbccdd7d5.18190e29da767a1c
    namespace: knative-serving
    resourceVersion: "52085"
    uid: 93d6b064-1370-4115-9f00-2c5219286575
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: net-istio-webhook
    namespace: knative-serving
    resourceVersion: "52072"
    uid: afcc3d27-02dd-47fd-9aa8-04d2a8ca2f50
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Scaled up replica set net-istio-webhook-5fbccdd7d5 to 2
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: net-istio-webhook.18190e29d866d702
    namespace: knative-serving
    resourceVersion: "52074"
    uid: ab81f30a-daa0-44f0-b819-25406b61d443
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:23.839848Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52022"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    to ip-10-0-25-180.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e29c209026e
    namespace: knative-serving
    resourceVersion: "52024"
    uid: d1bfad39-bc2a-4d36-9529-0b687b53bc0b
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52028"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Add eth0 [10.128.2.34/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e29e6de5c21
    namespace: knative-serving
    resourceVersion: "52098"
    uid: aeca177b-e20d-4ff2-b229-c0fda3535b63
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:24Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{migrate}
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52023"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-storage-version-migration:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:24Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e29e85d628a
    namespace: knative-serving
    resourceVersion: "52104"
    uid: 0622d041-8dbd-4c85-beb4-3bac2ff37da3
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{migrate}
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52023"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-storage-version-migration:knative-v1.14"
    in 2.397s (2.397s including waiting). Image size: 141535529 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e2a7747d4ae
    namespace: knative-serving
    resourceVersion: "52198"
    uid: 9e4ce8b5-ce74-4c07-ac47-b03088edc954
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{migrate}
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52023"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Created container migrate
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e2a7c87706d
    namespace: knative-serving
    resourceVersion: "52200"
    uid: 04bc2131-4118-49f3-86d5-e5917351c519
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:26Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{migrate}
    kind: Pod
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv
    namespace: knative-serving
    resourceVersion: "52023"
    uid: b7eeca70-09fd-4b4b-8627-cc2996279fc4
  kind: Event
  lastTimestamp: "2025-01-09T14:58:26Z"
  message: Started container migrate
  metadata:
    creationTimestamp: "2025-01-09T14:58:26Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:26Z"
    name: storage-version-migration-serving-serving-latest-1.34.1-kfpqv.18190e2a7d51dadd
    namespace: knative-serving
    resourceVersion: "52202"
    uid: da818592-1b7b-48f1-b986-c372b5edc9a2
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-25-180.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-25-180.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: batch/v1
    kind: Job
    name: storage-version-migration-serving-serving-latest-1.34.1
    namespace: knative-serving
    resourceVersion: "52020"
    uid: 2a70f9d6-5d45-4e6e-b024-7993cb34d33c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: 'Created pod: storage-version-migration-serving-serving-latest-1.34.1-kfpqv'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: storage-version-migration-serving-serving-latest-1.34.1.18190e29c1c4020b
    namespace: knative-serving
    resourceVersion: "52025"
    uid: 33a26f81-8f6d-42f5-a396-18d363d6d0a3
  reason: SuccessfulCreate
  reportingComponent: job-controller
  reportingInstance: ""
  source:
    component: job-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:29Z"
  involvedObject:
    apiVersion: batch/v1
    kind: Job
    name: storage-version-migration-serving-serving-latest-1.34.1
    namespace: knative-serving
    resourceVersion: "52274"
    uid: 2a70f9d6-5d45-4e6e-b024-7993cb34d33c
  kind: Event
  lastTimestamp: "2025-01-09T14:58:29Z"
  message: Job completed
  metadata:
    creationTimestamp: "2025-01-09T14:58:29Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:29Z"
    name: storage-version-migration-serving-serving-latest-1.34.1.18190e2b1a02ae42
    namespace: knative-serving
    resourceVersion: "52280"
    uid: fc40e20b-995f-4ef8-bf10-f79c8b44872a
  reason: Completed
  reportingComponent: job-controller
  reportingInstance: ""
  source:
    component: job-controller
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:37.933940Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52513"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/webhook-7bccb96f5b-p5w68 to ip-10-0-83-16.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: webhook-7bccb96f5b-p5w68.18190e2d0a1bc913
    namespace: knative-serving
    resourceVersion: "52518"
    uid: e975a13b-5075-47e8-a26a-496548acdee6
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52526"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Add eth0 [10.130.2.25/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: webhook-7bccb96f5b-p5w68.18190e2d4b14a2e7
    namespace: knative-serving
    resourceVersion: "52546"
    uid: bff7db68-216e-431e-8fba-9c4094045a7e
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:39Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:39Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-webhook:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:39Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:39Z"
    name: webhook-7bccb96f5b-p5w68.18190e2d4dc5c78b
    namespace: knative-serving
    resourceVersion: "52550"
    uid: 77941580-975f-46ae-88bb-b4b1988beb88
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-webhook:knative-v1.14"
    in 2.277s (2.277s including waiting). Image size: 159400161 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2dd57fff1d
    namespace: knative-serving
    resourceVersion: "52682"
    uid: c8f42605-0700-48bf-8dc2-e6c459eacee7
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Created container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2ddb0ad45b
    namespace: knative-serving
    resourceVersion: "52685"
    uid: 8260a4c9-a193-4cd3-b5ea-0c7fc3bd49f0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Started container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2ddbd304f2
    namespace: knative-serving
    resourceVersion: "52686"
    uid: 853b48f9-3557-45b1-bebe-3a95db05ee32
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Container image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    already present on machine
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2ddbde289c
    namespace: knative-serving
    resourceVersion: "52687"
    uid: 182d3093-e69c-4261-a068-23b0a942bb39
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2de23eb598
    namespace: knative-serving
    resourceVersion: "52691"
    uid: 1c112e74-b1ab-4861-90a1-295f31bffb6d
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:41Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-p5w68
    namespace: knative-serving
    resourceVersion: "52514"
    uid: 9a5a313e-f2b9-4745-8bc8-f32f24aa6cf1
  kind: Event
  lastTimestamp: "2025-01-09T14:58:41Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:41Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:41Z"
    name: webhook-7bccb96f5b-p5w68.18190e2de31692b4
    namespace: knative-serving
    resourceVersion: "52694"
    uid: 188253af-41f9-4ca8-8c4c-ce699bc02b30
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-83-16.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-83-16.ec2.internal
  type: Normal
- action: Binding
  apiVersion: v1
  eventTime: "2025-01-09T14:58:23.185886Z"
  firstTimestamp: null
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51973"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: null
  message: Successfully assigned knative-serving/webhook-7bccb96f5b-tksl4 to ip-10-0-63-72.ec2.internal
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: events.k8s.io/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:action: {}
        f:eventTime: {}
        f:note: {}
        f:reason: {}
        f:regarding: {}
        f:reportingController: {}
        f:reportingInstance: {}
        f:type: {}
      manager: kube-scheduler
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: webhook-7bccb96f5b-tksl4.18190e299b0e4e92
    namespace: knative-serving
    resourceVersion: "51981"
    uid: 4672dbd3-6935-4db0-8898-a2a09ddacddd
  reason: Scheduled
  reportingComponent: default-scheduler
  reportingInstance: default-scheduler-ip-10-0-13-186
  source: {}
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:24Z"
  message: 'MountVolume.SetUp failed for volume "secret-webhook-sm-service-tls" :
    secret "webhook-sm-service-tls" not found'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:24Z"
    name: webhook-7bccb96f5b-tksl4.18190e29a93b4980
    namespace: knative-serving
    resourceVersion: "52127"
    uid: 07b3eacb-9131-4fbb-96c5-eb27146977c3
  reason: FailedMount
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Warning
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51984"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Add eth0 [10.131.0.22/23] from ovn-kubernetes
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: multus-daemon
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: webhook-7bccb96f5b-tksl4.18190e2a9f846ca3
    namespace: knative-serving
    resourceVersion: "52221"
    uid: 37a5418c-f47b-4271-ab34-a62a2e8f50bf
  reason: AddedInterface
  reportingComponent: multus
  reportingInstance: ""
  source:
    component: multus
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:27Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:27Z"
  message: Pulling image "registry.ci.openshift.org/openshift/knative-serving-webhook:knative-v1.14"
  metadata:
    creationTimestamp: "2025-01-09T14:58:27Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:27Z"
    name: webhook-7bccb96f5b-tksl4.18190e2aad49c66d
    namespace: knative-serving
    resourceVersion: "52228"
    uid: 2730f37f-dc69-40b8-bbc6-9fd59b9f48e4
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/openshift/knative-serving-webhook:knative-v1.14"
    in 7.858s (7.858s including waiting). Image size: 159400161 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: webhook-7bccb96f5b-tksl4.18190e2c81b4c53f
    namespace: knative-serving
    resourceVersion: "52432"
    uid: 8bb1399f-2efe-4ded-bd14-d0b917050a85
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Created container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: webhook-7bccb96f5b-tksl4.18190e2c8b19f058
    namespace: knative-serving
    resourceVersion: "52436"
    uid: f4242751-b1c3-4744-866d-ecdfec1f2a76
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{webhook}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Started container webhook
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: webhook-7bccb96f5b-tksl4.18190e2c8c59c520
    namespace: knative-serving
    resourceVersion: "52438"
    uid: 99bee585-448e-4906-93c2-17cfefcbc295
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:35Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:35Z"
  message: Pulling image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
  metadata:
    creationTimestamp: "2025-01-09T14:58:35Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:35Z"
    name: webhook-7bccb96f5b-tksl4.18190e2c8c687345
    namespace: knative-serving
    resourceVersion: "52439"
    uid: 506a1cb8-a9c1-44ed-922e-507807b3ccc2
  reason: Pulling
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: 'Successfully pulled image "registry.ci.openshift.org/origin/4.15:kube-rbac-proxy"
    in 7.975s (7.975s including waiting). Image size: 498322628 bytes.'
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: webhook-7bccb96f5b-tksl4.18190e2e67cf2809
    namespace: knative-serving
    resourceVersion: "52770"
    uid: b42e7add-b382-475d-8332-3518c14ff266
  reason: Pulled
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Created container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: webhook-7bccb96f5b-tksl4.18190e2e6f747923
    namespace: knative-serving
    resourceVersion: "52781"
    uid: b2022041-e921-4d41-814c-df85ba5a42e0
  reason: Created
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:43Z"
  involvedObject:
    apiVersion: v1
    fieldPath: spec.containers{kube-rbac-proxy}
    kind: Pod
    name: webhook-7bccb96f5b-tksl4
    namespace: knative-serving
    resourceVersion: "51978"
    uid: 56a1c212-d872-49bd-a90c-89af2d99c2d2
  kind: Event
  lastTimestamp: "2025-01-09T14:58:43Z"
  message: Started container kube-rbac-proxy
  metadata:
    creationTimestamp: "2025-01-09T14:58:43Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:reportingInstance: {}
        f:source:
          f:component: {}
          f:host: {}
        f:type: {}
      manager: kubelet
      operation: Update
      time: "2025-01-09T14:58:43Z"
    name: webhook-7bccb96f5b-tksl4.18190e2e7074e5c2
    namespace: knative-serving
    resourceVersion: "52783"
    uid: 395adfcc-264e-4e7a-b626-167e7e883800
  reason: Started
  reportingComponent: kubelet
  reportingInstance: ip-10-0-63-72.ec2.internal
  source:
    component: kubelet
    host: ip-10-0-63-72.ec2.internal
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: webhook-7bccb96f5b
    namespace: knative-serving
    resourceVersion: "51970"
    uid: 50b28db3-7552-4321-9a73-03eab4a66f52
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: 'Created pod: webhook-7bccb96f5b-tksl4'
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: webhook-7bccb96f5b.18190e2999ccd617
    namespace: knative-serving
    resourceVersion: "51975"
    uid: a84657ef-cb96-453e-ad57-a82d0690c032
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: ReplicaSet
    name: webhook-7bccb96f5b
    namespace: knative-serving
    resourceVersion: "52510"
    uid: 50b28db3-7552-4321-9a73-03eab4a66f52
  kind: Event
  lastTimestamp: "2025-01-09T14:58:37Z"
  message: 'Created pod: webhook-7bccb96f5b-p5w68'
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: webhook-7bccb96f5b.18190e2d0958ac7b
    namespace: knative-serving
    resourceVersion: "52516"
    uid: 055e3489-1091-45d0-8d65-e67b9122e00e
  reason: SuccessfulCreate
  reportingComponent: replicaset-controller
  reportingInstance: ""
  source:
    component: replicaset-controller
  type: Normal
- apiVersion: v1
  count: 2
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:22Z"
  involvedObject:
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    name: webhook-pdb
    namespace: knative-serving
    resourceVersion: "51960"
    uid: e1b58ed1-ba98-4ede-8cc2-a5154ae7b9cf
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: No matching pods found
  metadata:
    creationTimestamp: "2025-01-09T14:58:22Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: webhook-pdb.18190e298fcf26ee
    namespace: knative-serving
    resourceVersion: "51964"
    uid: e945391d-c623-4a04-8952-9789a6877f79
  reason: NoPods
  reportingComponent: controllermanager
  reportingInstance: ""
  source:
    component: controllermanager
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:23Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: webhook
    namespace: knative-serving
    resourceVersion: "51969"
    uid: bc3630d9-1e21-4f5f-81f8-15d5538b2eff
  kind: Event
  lastTimestamp: "2025-01-09T14:58:23Z"
  message: Scaled up replica set webhook-7bccb96f5b to 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:23Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:23Z"
    name: webhook.18190e2998b2cadb
    namespace: knative-serving
    resourceVersion: "51972"
    uid: 2c7bbb51-724d-426a-9d57-b8aa575f30f1
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:37Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: webhook
    namespace: knative-serving
    resourceVersion: "51957"
    uid: e856d7c5-bbe0-437a-920c-dd06a01eeea5
  kind: Event
  lastTimestamp: "2025-01-09T14:58:37Z"
  message: 'New size: 2; reason: Current number of replicas below Spec.MinReplicas'
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: webhook.18190e2d069d6b48
    namespace: knative-serving
    resourceVersion: "52507"
    uid: d33b5151-36af-465e-b5f6-cbc053b0b9e8
  reason: SuccessfulRescale
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Normal
- apiVersion: v1
  count: 1
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:37Z"
  involvedObject:
    apiVersion: apps/v1
    kind: Deployment
    name: webhook
    namespace: knative-serving
    resourceVersion: "52506"
    uid: bc3630d9-1e21-4f5f-81f8-15d5538b2eff
  kind: Event
  lastTimestamp: "2025-01-09T14:58:37Z"
  message: Scaled up replica set webhook-7bccb96f5b to 2 from 1
  metadata:
    creationTimestamp: "2025-01-09T14:58:37Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:58:37Z"
    name: webhook.18190e2d08535371
    namespace: knative-serving
    resourceVersion: "52512"
    uid: 13310265-bf7c-44fb-b969-b7e8c41e465c
  reason: ScalingReplicaSet
  reportingComponent: deployment-controller
  reportingInstance: ""
  source:
    component: deployment-controller
  type: Normal
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:52Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: webhook
    namespace: knative-serving
    resourceVersion: "52900"
    uid: e856d7c5-bbe0-437a-920c-dd06a01eeea5
  kind: Event
  lastTimestamp: "2025-01-09T14:59:22Z"
  message: 'failed to get cpu utilization: unable to get metrics for resource cpu:
    no metrics returned from resource metrics API'
  metadata:
    creationTimestamp: "2025-01-09T14:58:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:59:22Z"
    name: webhook.18190e30862e1238
    namespace: knative-serving
    resourceVersion: "53377"
    uid: 966da454-0498-459f-a2f8-c851d4dce736
  reason: FailedGetResourceMetric
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Warning
- apiVersion: v1
  count: 3
  eventTime: null
  firstTimestamp: "2025-01-09T14:58:52Z"
  involvedObject:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: webhook
    namespace: knative-serving
    resourceVersion: "52900"
    uid: e856d7c5-bbe0-437a-920c-dd06a01eeea5
  kind: Event
  lastTimestamp: "2025-01-09T14:59:22Z"
  message: 'invalid metrics (1 invalid out of 1), first error is: failed to get cpu
    resource metric value: failed to get cpu utilization: unable to get metrics for
    resource cpu: no metrics returned from resource metrics API'
  metadata:
    creationTimestamp: "2025-01-09T14:58:52Z"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:count: {}
        f:firstTimestamp: {}
        f:involvedObject: {}
        f:lastTimestamp: {}
        f:message: {}
        f:reason: {}
        f:reportingComponent: {}
        f:source:
          f:component: {}
        f:type: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-01-09T14:59:22Z"
    name: webhook.18190e3086cf1073
    namespace: knative-serving
    resourceVersion: "53378"
    uid: e1dcd7b1-d955-424e-905e-ee022fddd217
  reason: FailedComputeMetricsReplicas
  reportingComponent: horizontal-pod-autoscaler
  reportingInstance: ""
  source:
    component: horizontal-pod-autoscaler
  type: Warning
kind: EventList
metadata:
  resourceVersion: "60709"
